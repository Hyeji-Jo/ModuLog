{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 말뭉치 합성 데이터\n",
    "\n",
    "### Json 타임스탬프에 맞춰서 오디오 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def process_json_file(json_path):\n",
    "    \"\"\"JSON 파일을 읽고 start_time 리스트를 반환\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    time_data = []\n",
    "    endtime = -1\n",
    "    \n",
    "    for speech in data.get('document', [{}])[0].get('utterance', []):\n",
    "        start_time = speech.get('start', 0)\n",
    "        end_time = speech.get('end', 0)\n",
    "\n",
    "        if start_time < endtime:\n",
    "            print(f\"{os.path.basename(json_path)}: speech overlap at {start_time}\")\n",
    "\n",
    "        time_data.append(start_time)\n",
    "        endtime = end_time\n",
    "    \n",
    "    return time_data\n",
    "\n",
    "def sort_wav_files(directory):\n",
    "    wav_files = [f for f in os.listdir(directory) if f.endswith('.wav')]\n",
    "    wav_files.sort(key=lambda x: int(x.split('.')[-2]))\n",
    "    return wav_files\n",
    "\n",
    "def merge_wav_files(json_file, json_dir, wav_base_dir, output_dir):\n",
    "    \"\"\"JSON 파일과 같은 SDRW ID 폴더의 WAV 파일을 start_time 순서로 합쳐 저장\"\"\"\n",
    "    sdrw_id = json_file.replace(\".json\", \"\")  # SDRW ID 추출\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "    wav_dir = os.path.join(wav_base_dir, sdrw_id)  # 해당 SDRW ID 폴더\n",
    "    output_file = os.path.join(output_dir, f\"{sdrw_id}_merged.wav\")\n",
    "\n",
    "    if not os.path.exists(wav_dir):\n",
    "        print(f\"Warning: WAV directory not found for {sdrw_id}\")\n",
    "        return\n",
    "\n",
    "    # JSON에서 start_time 리스트 가져오기\n",
    "    start_times = process_json_file(json_path)\n",
    "\n",
    "    # WAV 파일 불러오기\n",
    "    wav_files = sort_wav_files(wav_dir)\n",
    "    \n",
    "    print(f\"{sdrw_id}: {len(wav_files)} WAV files, {len(start_times)} timestamps\")\n",
    "\n",
    "    if len(wav_files) != len(start_times):\n",
    "        print(f\"⚠ Warning: Mismatch in WAV count for {sdrw_id}. {len(wav_files)} wavs vs {len(start_times)} timestamps.\")\n",
    "\n",
    "    # 초기 combined_audio 길이 조정\n",
    "    combined_audio = AudioSegment.silent(duration=max(start_times) * 1000 + 1000)\n",
    "    max_duration = 0  # 전체 길이를 추적하기 위한 변수\n",
    "\n",
    "    for wav_file, start_time in zip(wav_files, start_times):\n",
    "        wav_path = os.path.join(wav_dir, wav_file)\n",
    "        try:\n",
    "            audio = AudioSegment.from_wav(wav_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {wav_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        start_ms = round(float(start_time) * 1000)  # 반올림 사용\n",
    "        print(f\"Processing {wav_file}, start_ms: {start_ms}, audio length: {len(audio)}\") #디버깅 정보 추가\n",
    "\n",
    "        combined_audio = combined_audio.overlay(audio, position=start_ms)\n",
    "        max_duration = max(max_duration, start_ms + len(audio))\n",
    "        print(f\"Combined audio length: {len(combined_audio)}\") #디버깅 정보 추가\n",
    "\n",
    "    # 최종 길이 맞추기 (마지막 오디오 이후에 무음 추가)\n",
    "    if len(combined_audio) < max_duration:\n",
    "        combined_audio += AudioSegment.silent(duration=max_duration - len(combined_audio))\n",
    "\n",
    "    # 최종 오디오 저장\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    combined_audio.export(output_file, format=\"wav\")\n",
    "    print(f\"✅ Merged {sdrw_id} saved as {output_file}\")\n",
    "\n",
    "# 디렉토리 설정\n",
    "json_dir = \"kor/json/\"\n",
    "wav_base_dir = \"kor/kor_corpus/\"\n",
    "output_dir = \"kor/output/\"\n",
    "\n",
    "json_files = [f for f in os.listdir(json_dir) if f.startswith('SDRW') and f.endswith('.json')]\n",
    "\n",
    "for json_file in json_files:\n",
    "    merge_wav_files(json_file, json_dir, wav_base_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 말뭉치 RTTM Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def json_to_rttm(json_file, json_dir, output_dir):\n",
    "    \"\"\"JSON 파일을 읽고 RTTM 포맷으로 변환 후 저장\"\"\"\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "    \n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    rttm_lines = []\n",
    "    data_name = os.path.splitext(json_file)[0]  \n",
    "\n",
    "    for speech in data.get('document', [{}])[0].get('utterance', []):\n",
    "        start_ms = float(speech.get('start', 0))\n",
    "        end_ms = float(speech.get('end', 0))\n",
    "        duration = round(end_ms - start_ms, 5)\n",
    "        speaker_id = speech.get('speaker_id', 'unknown')\n",
    "\n",
    "        # RTTM 포맷 라인 생성\n",
    "        rttm_line = f\"SPEAKER {data_name} 1 {start_ms:.3f} {duration:.3f} <NA> <NA> {speaker_id} <NA>\"\n",
    "        rttm_lines.append(rttm_line)\n",
    "\n",
    "    # RTTM 파일 저장\n",
    "    rttm_file = os.path.join(output_dir, f\"{data_name}.rttm\")\n",
    "    with open(rttm_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(rttm_lines) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ RTTM 파일 생성 완료: {rttm_file}\")\n",
    "\n",
    "# 디렉토리 설정\n",
    "json_dir = \"kor/json/\"\n",
    "output_dir = \"kor/rttm/\"\n",
    "\n",
    "# 출력 디렉토리 생성 (존재하지 않으면)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# JSON 파일 리스트 가져오기\n",
    "json_files = [f for f in os.listdir(json_dir) if f.startswith('SDRW') and f.endswith('.json')]\n",
    "\n",
    "# 변환 실행\n",
    "for json_file in json_files:\n",
    "    json_to_rttm(json_file, json_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alimeeting RTTM Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from praatio import textgrid\n",
    "\n",
    "def tg_to_rttm(tg_file, text_dir, output_dir):\n",
    "    tg_path = os.path.join(text_dir, tg_file)\n",
    "    \n",
    "    tg = textgrid.openTextgrid(tg_path, False)\n",
    "    all_log = []\n",
    "    for name in tg.tierNames:\n",
    "        entries = tg._tierDict[name].entries\n",
    "        for entry in entries:\n",
    "            duration = round(float(entry.end) - float(entry.start), 2)\n",
    "            all_log.append((entry.start, duration, name, entry.label))\n",
    "\n",
    "    all_log.sort(key=lambda x: x[0])\n",
    "\n",
    "    rttm_lines = []\n",
    "    data_name = tg_file.replace(\".TextGrid\", \"\")\n",
    "\n",
    "    for i, log in enumerate(all_log):\n",
    "        start_time, duration, speaker_id, label = log\n",
    "        rttm_line = f\"SPEAKER {data_name} 1 {start_time:.2f} {duration:.2f} <NA> <NA> {speaker_id} <NA>\"\n",
    "        rttm_lines.append(rttm_line)\n",
    "\n",
    "    # RTTM 파일 저장\n",
    "    rttm_file = os.path.join(output_dir, f\"{data_name}.rttm\")\n",
    "    with open(rttm_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(rttm_lines) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ RTTM 파일 생성 완료: {rttm_file}\")\n",
    "    \n",
    "text_dir = \"Train_Ali_far/textgrid_dir/\"\n",
    "output_dir = \"Train_Ali_far/rttm/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "tg_files = [f for f in os.listdir(text_dir) if f.endswith('.TextGrid')]\n",
    "\n",
    "for tg_file in tg_files:\n",
    "    tg_to_rttm(tg_file, text_dir, output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap 합성\n",
    "- 총 데이터의 30%\n",
    "- 각 발화의 30% ~ 40% 오버랩\n",
    "- 랜덤 샘플링\n",
    "- 포맷 : 발화자, 발화시작, 발화끝, 발화내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "text_dir = \"Ali/Train_Ali_far/rttm/\"\n",
    "train_dir = \"Ali/Train_Ali_far/rttm/train/\"\n",
    "test_dir = \"Ali/Train_Ali_far/rttm/test/\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "tg_files = [f for f in os.listdir(text_dir) if f.endswith('.rttm')]\n",
    "\n",
    "# split dataset\n",
    "train_ratio = 0.9 \n",
    "train_count = int(len(tg_files) * train_ratio)\n",
    "\n",
    "train_files = tg_files[:train_count]\n",
    "test_files = tg_files[train_count:]\n",
    "\n",
    "\n",
    "with open(\"Ali/Train_Ali_far/train_list.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(train_files))\n",
    "\n",
    "# test list txt file\n",
    "with open(\"Ali/Train_Ali_far/test_list.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(test_files))\n",
    "\n",
    "# move files\n",
    "for f in train_files:\n",
    "    os.rename(os.path.join(text_dir, f), os.path.join(train_dir, f))\n",
    "\n",
    "for f in test_files:\n",
    "    os.rename(os.path.join(text_dir, f), os.path.join(test_dir, f))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
