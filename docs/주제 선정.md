# 주제 후보
- 실시간 번역
- 다국어 회의
- **다국어 회의록 요약**
- AI 고객센터
- 노인 인공지능 전화 서비스

# 자료 조사
## 다중발화 음성인식
### [Speech Recognition and Multi-Speaker Diarization of Long Conversations](https://github.com/calclavia/tal-asrd)

### [Cross-Speaker Encoding Network for Multi-Talker Speech Recognition](https://github.com/kjw11/csenet-asr)
- 기존의 다중 화자 음성인식 모델의 접근법
  - SIMO(Single-Input Multiple-Output) 모델 : 여러 개의 분리된 인코더를 통해 처리
  - SISO(Single-Input Single-Output) 모델 : 주로 어템션 기반 인코더-디코더 아카텍처 사용
  - 과정 : 음성 분리 -> 화자 분리 -> 음성인식
- 본 논문은 SIMO 모델의 한계를 극복
- LibrispeechMix 데이터셋 사용
  - 훈련 데이터: 960시간
  - 검증 데이터: 10시간
  - 테스트 데이터: 10시간
  - 각 발화를 다른 화자의 발화와 혼합하여 중첩 발화(overlapping speech) 생성
  - 신호 대 잡음비(SNR, Signal-to-Noise Ratio)를 -5 dB ~ 5 dB 범위에서 설정하여 다양한 중첩 강도를 시뮬레이션 
- **CSE 모델 특징**
  - 기존 SIMO 모델의 경우 각 화자의 음성을 개별적으로 처리하지만, CSE 네트워크는 전체 발화 내의 모든 화자의 특징을 통합하여 문맥정보를 더 풍부하게 학습
  - 중첩이 많을수록 성능이 좋으며, 중첩이 0~50%로 낮은 경우 성능이 일반 모델보다 떨어짐
  - 화자 인식 인코더 -> 화자간 의존성 학습 -> 텍스트 디코더
    - 화자 인식 인코더 : Transformer 기반 구조 / CNN 기반 전처리
    - 화자간 의존성 학습 : Cross-Attention 메커니즘을 활용하여 각 화자의 임베딩을 다른 화자의 임베딩을 고려하여 학습
    - 텍스트 디코더 : Attention 기반 /  Serialized Output Training (SOT) 방식을 적용
- 본 논문에서 사용된 모델은 Conformer (Transformer + CNN )
  - Whisper의 경우 SIMO 처럼 동작하기 위해 **Pyannote-Diarization** 패키지 사용 필요
  - 본 논문을 whisper로 변경하려면 전체 입출력을 바꿔야 함
- License : 연구 및 서비스개발에 자유롭게 사용 가능
- GPT의 조언
  -  Conformer를 다국어 데이터셋으로 파인튜닝 (Fine-tuning)
  -  Conformer 모델을 그대로 사용하되, Whisper 같은 다국어 ASR 모델과 결합

### [Acoustic modeling for Overlapping Speech Recognition- JHU Chime-5 Challenge System](https://github.com/fgnt/nara_wpe)
원거리 및 중첩 음성 환경에서 음성 인식 성능을 향상시키기 위해 다양한 **데이터 증강, 신경망 모델 개선, 전처리 기법**을 적용하고 Kaldi 기반 새로운 ASR 시스템을 개발

- **환경**
    - 마이크 방향을 향하지 않은 화자도 존재→ 왜곡 있음
    - 집안의 소음이 존재
    - 다양한 위치에서 녹음

The speech data consists of real 4-people dinner party conversations recorded using linear array microphones, and annotated with speech
start/end times, the speaker labels and speech transcription.

- **데이터 증강**
    - chime-5
    - Kaldi → 채택
        - 합성 RIR 사용
        - 외부 소음 데이터 (MUSAN) 추가
- **Neural Network Architentures**
    
    : 화자분리는 X
    
    - TDNN
    - TDNN + LSTM
    - TDNN + F
    - DNN + TDNN + LSTM

### [Speaker Embedding-aware Neural Diarization: an Efficient Framework for Overlapping Speech Diarization in Meeting Scenarios](https://github.com/modelscope/FunASR)

## 다중발화 성능
- [On Word Error Rate Definitions and their Efficient Computation for Multi-Speaker Speech Recognition Systems](https://github.com/fgnt/meeteval)
