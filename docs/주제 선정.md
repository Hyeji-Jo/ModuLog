# 주제 후보
- 실시간 번역
- 다국어 회의
- **다국어 회의록 요약**
- AI 고객센터
- 노인 인공지능 전화 서비스

# 자료 조사
## 다중발화 음성인식
### [Speech Recognition and Multi-Speaker Diarization of Long Conversations](https://github.com/calclavia/tal-asrd)

### [Cross-Speaker Encoding Network for Multi-Talker Speech Recognition](https://github.com/kjw11/csenet-asr)
- 기존의 다중 화자 음성인식 모델의 접근법
  - SIMO(Single-Input Multiple-Output) 모델 : 여러 개의 분리된 인코더를 통해 처리
  - SISO(Single-Input Single-Output) 모델 : 주로 어템션 기반 인코더-디코더 아카텍처 사용
  - 과정 : 음성 분리 -> 화자 분리 -> 음성인식
- 본 논문은 SIMO 모델의 한계를 극복
- LibrispeechMix 데이터셋 사용
  - 훈련 데이터: 960시간
  - 검증 데이터: 10시간
  - 테스트 데이터: 10시간
  - 각 발화를 다른 화자의 발화와 혼합하여 중첩 발화(overlapping speech) 생성
  - 신호 대 잡음비(SNR, Signal-to-Noise Ratio)를 -5 dB ~ 5 dB 범위에서 설정하여 다양한 중첩 강도를 시뮬레이션 
- **CSE 모델 특징**
  - 기존 SIMO 모델의 경우 각 화자의 음성을 개별적으로 처리하지만, CSE 네트워크는 전체 발화 내의 모든 화자의 특징을 통합하여 문맥정보를 더 풍부하게 학습
  - 중첩이 많을수록 성능이 좋으며, 중첩이 0~50%로 낮은 경우 성능이 일반 모델보다 떨어짐
  - 화자 인식 인코더 -> 화자간 의존성 학습 -> 텍스트 디코더
    - 화자 인식 인코더 : Transformer 기반 구조 / CNN 기반 전처리
    - 화자간 의존성 학습 : Cross-Attention 메커니즘을 활용하여 각 화자의 임베딩을 다른 화자의 임베딩을 고려하여 학습
    - 텍스트 디코더 : Attention 기반 /  Serialized Output Training (SOT) 방식을 적용
- Whisper의 경우 SIMO 처럼 동작하기 위해 Pyannote-Diarization 패키지 사용 필요

### [Acoustic modeling for Overlapping Speech Recognition- JHU Chime-5 Challenge System](https://github.com/fgnt/nara_wpe)

### [Speaker Embedding-aware Neural Diarization: an Efficient Framework for Overlapping Speech Diarization in Meeting Scenarios](https://github.com/modelscope/FunASR)

## 다중발화 성능
- [On Word Error Rate Definitions and their Efficient Computation for Multi-Speaker Speech Recognition Systems](https://github.com/fgnt/meeteval)
